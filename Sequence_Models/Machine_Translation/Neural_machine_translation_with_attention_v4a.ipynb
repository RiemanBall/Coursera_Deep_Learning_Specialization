{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "Hi! This notebook is adapted from the Machine Translation Assignment in Coursera-Deep Learning Courser, Sequence Model. Most of codes, including the supporting nmt_utils.py, are rewritten to tensorflow-based. I still used a lot Keras functions via tensorflow tho :P.\n",
    "\n",
    "In this notebook, \n",
    "* You will build a Neural Machine Translation (NMT) model to translate human-readable dates (\"25th of June, 2009\") into machine-readable dates (\"2009-06-25\"). \n",
    "* You will do this using an attention model, one of the most sophisticated sequence-to-sequence models. \n",
    "\n",
    "This notebook was produced together with NVIDIA's Deep Learning Institute. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load all the packages you will need for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Bidirectional, Embedding, Input, LSTM, Softmax\n",
    "from tensorflow.keras.layers import Reshape, Dense, RepeatVector, Concatenate, Dot\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Translating human readable dates into machine readable dates\n",
    "\n",
    "* The model you will build here could be used to translate from one language to another, such as translating from English to Hindi. \n",
    "* However, language translation requires massive datasets and usually takes days of training on GPUs. \n",
    "* To give you a place to experiment with these models without using massive datasets, we will perform a simpler \"date translation\" task. \n",
    "* The network will input a date written in a variety of possible formats (*e.g. \"the 29th of August 1958\", \"03/30/1968\", \"24 JUNE 1987\"*) \n",
    "* The network will translate them into standardized, machine readable dates (*e.g. \"1958-08-29\", \"1968-03-30\", \"1987-06-24\"*). \n",
    "* We will have the network learn to output dates in the common machine-readable format YYYY-MM-DD. \n",
    "\n",
    "<!-- \n",
    "Take a look at [nmt_utils.py](./nmt_utils.py) to see all the formatting. Count and figure out how the formats work, you will need this knowledge later. !--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Dataset\n",
    "\n",
    "We will train the model on a dataset of 10,000 human readable dates and their equivalent, standardized, machine readable dates. Let's run the following cells to load the dataset and print some examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 23184.31it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9 may 1998', '1998-05-09'),\n",
       " ('10.11.19', '2019-11-10'),\n",
       " ('9/10/70', '1970-09-10'),\n",
       " ('saturday april 28 1990', '1990-04-28'),\n",
       " ('thursday january 26 1995', '1995-01-26'),\n",
       " ('monday march 7 1983', '1983-03-07'),\n",
       " ('sunday may 22 1988', '1988-05-22'),\n",
       " ('08 jul 2008', '2008-07-08'),\n",
       " ('8 sep 1999', '1999-09-08'),\n",
       " ('thursday january 1 1981', '1981-01-01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've loaded:\n",
    "- `dataset`: a list of tuples of (human readable date, machine readable date).\n",
    "- `human_vocab`: a python dictionary mapping all characters used in the human readable dates to an integer-valued index.\n",
    "- `machine_vocab`: a python dictionary mapping all characters used in machine readable dates to an integer-valued index. \n",
    "    - **Note**: These indices are not necessarily consistent with `human_vocab`. \n",
    "- `inv_machine_vocab`: the inverse dictionary of `machine_vocab`, mapping from indices back to characters. \n",
    "\n",
    "Let's preprocess the data and map the raw text data into the index values. \n",
    "- We will set Tx=30 \n",
    "    - We assume Tx is the maximum length of the human readable date.\n",
    "    - If we get a longer input, we would have to truncate it.\n",
    "- We will set Ty=10\n",
    "    - \"YYYY-MM-DD\" is 10 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have:\n",
    "- `X`: a processed version of the human readable dates in the training set.\n",
    "    - Each character in X is replaced by an index (integer) mapped to the character using `human_vocab`. \n",
    "    - Each date is padded to ensure a length of $T_x$ using a special character (< pad >). \n",
    "    - `X.shape = (m, Tx)` where m is the number of training examples in a batch.\n",
    "- `Y`: a processed version of the machine readable dates in the training set.\n",
    "    - Each character is replaced by the index (integer) it is mapped to in `machine_vocab`. \n",
    "    - `Y.shape = (m, Ty)`. \n",
    "- `Xoh`: one-hot version of `X`\n",
    "    - Each index in `X` is converted to the one-hot representation (if the index is 2, the one-hot version has the index position 2 set to 1, and the remaining positions are 0.\n",
    "    - `Xoh.shape = (m, Tx, len(human_vocab))`\n",
    "- `Yoh`: one-hot version of `Y`\n",
    "    - Each index in `Y` is converted to the one-hot representation. \n",
    "    - `Yoh.shape = (m, Tx, len(machine_vocab))`. \n",
    "    - `len(machine_vocab) = 11` since there are 10 numeric digits (0 to 9) and the `-` symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's also look at some examples of preprocessed training examples. \n",
    "* Feel free to play with `index` in the cell below to navigate the dataset and see how source/target dates are preprocessed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 9 may 1998\n",
      "Target date: 1998-05-09\n",
      "\n",
      "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Neural machine translation with attention\n",
    "\n",
    "* If you had to translate a book's paragraph from French to English, you would not read the whole paragraph, then close the book and translate. \n",
    "* Even during the translation process, you would read/re-read and focus on the parts of the French paragraph corresponding to the parts of the English you are writing down. \n",
    "* The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. \n",
    "\n",
    "\n",
    "### 2.1 - Attention mechanism\n",
    "\n",
    "In this part, you will implement the attention mechanism presented in the lecture videos. \n",
    "* Here is a figure to remind you how the model works. The exact implementation is slightly different from the figure.\n",
    "    * The diagram on the left shows the attention model. \n",
    "    * The diagram on the right shows what one \"attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "    * The attention variables $\\alpha^{\\langle t, t' \\rangle}$ are used to compute the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$). \n",
    "\n",
    "<table>\n",
    "<td> \n",
    "<img src=\"images/attn_model.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "<td> \n",
    "<img src=\"images/attn_mechanism.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "</table>\n",
    "<caption><center> **Figure 1**: Neural machine translation with attention</center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some properties of the model that you may notice: \n",
    "\n",
    "#### Pre-attention and Post-attention LSTMs on both sides of the attention mechanism\n",
    "- There are two separate LSTMs in this model (see diagram on the left): pre-attention and post-attention LSTMs.\n",
    "- *Pre-attention* Bi-LSTM is the one at the bottom of the picture is a Bi-directional LSTM and comes *before* the attention mechanism.\n",
    "    - The attention mechanism is shown in the middle of the left-hand diagram.\n",
    "    - The pre-attention Bi-LSTM goes through $T_x$ time steps\n",
    "- *Post-attention* LSTM: at the top of the diagram comes *after* the attention mechanism. \n",
    "    - The post-attention LSTM goes through $T_y$ time steps. \n",
    "\n",
    "- The post-attention LSTM passes the hidden state $s^{\\langle t \\rangle}$ and cell state $c^{\\langle t \\rangle}$ from one time step to the next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An LSTM has both a hidden state and cell state\n",
    "* In the lecture videos, we were using only a basic RNN for the post-attention sequence model\n",
    "    * This means that the state captured by the RNN was outputting only the hidden state $s^{\\langle t\\rangle}$. \n",
    "* In this assignment, we are using an LSTM instead of a basic RNN.\n",
    "    * So the LSTM has both the hidden state $s^{\\langle t\\rangle}$ and the cell state $c^{\\langle t\\rangle}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each time step does not use predictions from the previous time step\n",
    "* Unlike previous text generation examples earlier in the course, in this model, the post-attention LSTM at time $t$ does not take the previous time step's prediction $y^{\\langle t-1 \\rangle}$ as input.\n",
    "* The post-attention LSTM at time 't' only takes the hidden state $s^{\\langle t\\rangle}$ and cell state $c^{\\langle t\\rangle}$ as input. \n",
    "* We have designed the model this way because unlike language generation (where adjacent characters are highly correlated) there isn't as strong a dependency between the previous character and the next character in a YYYY-MM-DD date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation of hidden states from the forward and backward pre-attention LSTMs\n",
    "- $\\overrightarrow{a}^{\\langle t \\rangle}$: hidden state of the forward-direction, pre-attention LSTM.\n",
    "- $\\overleftarrow{a}^{\\langle t \\rangle}$: hidden state of the backward-direction, pre-attention LSTM.\n",
    "- $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}, \\overleftarrow{a}^{\\langle t \\rangle}]$: the concatenation of the activations of both the forward-direction $\\overrightarrow{a}^{\\langle t \\rangle}$ and backward-directions $\\overleftarrow{a}^{\\langle t \\rangle}$ of the pre-attention Bi-LSTM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing \"energies\" $e^{\\langle t, t' \\rangle}$ as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$\n",
    "- Recall in the lesson videos \"Attention Model\", at time 6:45 to 8:16, the definition of \"e\" as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$.\n",
    "    - \"e\" is called the \"energies\" variable.\n",
    "    - $s^{\\langle t-1 \\rangle}$ is the hidden state of the post-attention LSTM\n",
    "    - $a^{\\langle t' \\rangle}$ is the hidden state of the pre-attention LSTM.\n",
    "    - $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ are fed into a simple neural network, which learns the function to output $e^{\\langle t, t' \\rangle}$.\n",
    "    - $e^{\\langle t, t' \\rangle}$ is then used when computing the attention $a^{\\langle t, t' \\rangle}$ that $y^{\\langle t \\rangle}$ should pay to $a^{\\langle t' \\rangle}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The diagram on the right of figure 1 uses a `RepeatVector` node to copy $s^{\\langle t-1 \\rangle}$'s value $T_x$ times.\n",
    "- Then it uses `Concatenation` to concatenate $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$.\n",
    "- The concatenation of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ is fed into a \"Dense\" layer, which computes $e^{\\langle t, t' \\rangle}$. \n",
    "- $e^{\\langle t, t' \\rangle}$ is then passed through a softmax to compute $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "- Note that the diagram doesn't explicitly show variable $e^{\\langle t, t' \\rangle}$, but $e^{\\langle t, t' \\rangle}$ is above the Dense layer and below the Softmax layer in the diagram in the right half of figure 1.\n",
    "- We'll explain how to use `RepeatVector` and `Concatenation` in Keras below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Details\n",
    "   \n",
    "Let's implement this neural translator. You will start by implementing two functions: `one_step_attention()` and `model()`.\n",
    "\n",
    "#### one_step_attention\n",
    "* The inputs to the one_step_attention at time step $t$ are:\n",
    "    - $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$: all hidden states of the pre-attention Bi-LSTM.\n",
    "    - $s^{<t-1>}$: the previous hidden state of the post-attention LSTM \n",
    "* one_step_attention computes:\n",
    "    - $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$: the attention weights\n",
    "    - $context^{ \\langle t \\rangle }$: the context vector:\n",
    "    \n",
    "$$context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n",
    "\n",
    "##### Clarifying 'context' and 'c'\n",
    "- In the lecture videos, the context was denoted $c^{\\langle t \\rangle}$\n",
    "- In the assignment, we are calling the context $context^{\\langle t \\rangle}$.\n",
    "    - This is to avoid confusion with the post-attention LSTM's internal memory cell variable, which is also denoted $c^{\\langle t \\rangle}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement `one_step_attention`\n",
    "\n",
    "**Exercise**: Implement `one_step_attention()`. \n",
    "\n",
    "* The function `model()` will call the layers in `one_step_attention()` $T_y$ using a for-loop.\n",
    "* It is important that all $T_y$ copies have the same weights. \n",
    "    * It should not reinitialize the weights every time. \n",
    "    * In other words, all $T_y$ steps should have shared weights. \n",
    "* Here's how you can implement layers with shareable weights in Keras:\n",
    "    1. Define the layer objects in a variable scope that is outside of the `one_step_attention` function.  For example, defining the objects as global variables would work.\n",
    "        - Note that defining these variables inside the scope of the function `model` would technically work, since `model` will then call the `one_step_attention` function.  For the purposes of making grading and troubleshooting easier, we are defining these as global variables.\n",
    "    2. Call these objects when propagating the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "dense1 = Dense(32, kernel_regularizer = 'l2', name = 'atten_W_a')\n",
    "dense2 = Dense(32, kernel_regularizer = 'l2', name = 'atten_W_t')\n",
    "scorer = Dense(1, activation = 'tanh', name = 'atten_scores')\n",
    "softmaxer = Softmax(axis = 1, name = 'attention_weights')\n",
    "repeater = RepeatVector(Tx)\n",
    "dotor1 = Dot(axes = -1)\n",
    "dotor2 = Dot(axes = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_step_attention\n",
    "\n",
    "def one_step_attention(a, ht_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot \n",
    "    product of the attention weights \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    ht_prev -- previous hidden state of the (post-attention) LSTM, numpy-array \n",
    "    of shape (m, n_t)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attention) LSTM cell\n",
    "    \"\"\"\n",
    "    # After reshape: (m, 1, n_s)\n",
    "    ht_prev = tf.expand_dims(ht_prev, axis = 1)\n",
    "    \n",
    "    # shape of scores: (m, Tx, 1)\n",
    "    scores = scorer(dense1(a) + dense2(ht_prev))\n",
    "    \n",
    "    # shape: (m, Tx, 1)\n",
    "    attention_weights = softmaxer(scores)\n",
    "    \n",
    "    # shape: (m, 1, 2 * n_a)\n",
    "    context = dotor2([attention_weights, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to check the expected output of `one_step_attention()` after you've coded the `model()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model\n",
    "* `model` first runs the input to an embedding layer, then feed the embedded input through a Bi-LSTM to get $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$. \n",
    "* Then, `model` calls `one_step_attention()` $T_y$ times using a `for` loop.  At each iteration of this loop:\n",
    "    - It gives the computed context vector $context^{<t>}$ to the post-attention LSTM.\n",
    "    - It runs the output of the post-attention LSTM through a dense layer with softmax activation.\n",
    "    - The softmax generates a prediction $\\hat{y}^{<t>}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `model()` as explained in the text above. Again, we have defined global layers that will share weights to be used in `model()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use these layers $T_y$ times in a `for` loop to generate the outputs, and their parameters will not be reinitialized. You will have to carry out the following steps: \n",
    "\n",
    "1. Embedding the input `X` to get embedded vector `embedded`.\n",
    "\n",
    "2. Propagate the input `embedded` into a bi-directional LSTM.\n",
    "    * [Bidirectional](https://keras.io/layers/wrappers/#bidirectional) \n",
    "    * [LSTM](https://keras.io/layers/recurrent/#lstm)\n",
    "    * Remember that we want the LSTM to return a full sequence instead of just the last hidden state.  \n",
    "    \n",
    "Sample code:\n",
    "\n",
    "```Python\n",
    "sequence_of_hidden_states = Bidirectional(LSTM(units=..., return_sequences=...))(the_input_X)\n",
    "```\n",
    "    \n",
    "3. Iterate for $t = 0, \\cdots, T_y-1$: \n",
    "    1. Call `one_step_attention()`, passing in the sequence of hidden states $[a^{\\langle 1 \\rangle},a^{\\langle 2 \\rangle}, ..., a^{ \\langle T_x \\rangle}]$ from the pre-attention bi-directional LSTM, and the previous hidden state $s^{<t-1>}$ from the post-attention LSTM to calculate the context vector $context^{<t>}$.\n",
    "    2. Give $context^{<t>}$ to the post-attention LSTM cell. \n",
    "        - Remember to pass in the previous hidden-state $s^{\\langle t-1\\rangle}$ and cell-states $c^{\\langle t-1\\rangle}$ of this LSTM \n",
    "        * This outputs the new hidden state $s^{<t>}$ and the new cell state $c^{<t>}$.  \n",
    "\n",
    "        Sample code:\n",
    "        ```Python\n",
    "        next_hidden_state, _ , next_cell_state = \n",
    "            post_activation_LSTM_cell(inputs=..., initial_state=[prev_hidden_state, prev_cell_state])\n",
    "        ```   \n",
    "        \n",
    "    3. Apply a dense, softmax layer to $s^{<t>}$, get the output.  \n",
    "        Sample code:\n",
    "        ```Python\n",
    "        output = output_layer(inputs=...)\n",
    "        ```\n",
    "    4. Save the output by adding it to the list of outputs.\n",
    "\n",
    "4. Create your Keras model instance.\n",
    "    * It should have one input:\n",
    "        * `X`, the inputs in index representation to the model, of shape ($T_{x}, )$\n",
    "        \n",
    "    * The output is the list of outputs.  \n",
    "    Sample code\n",
    "    ```Python\n",
    "    model = Model(inputs=[...,...,...], outputs=...)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 64 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
    "n_t = 2 * n_a # number of units for the post-attention LSTM's hidden state \"t\"\n",
    "dp_rate = 0.0\n",
    "embed_dim = 16\n",
    "\n",
    "# Post attention LSTM cell.\n",
    "post_activation_LSTM_cell = LSTM(n_t, return_state = True, dropout = dp_rate) # post-attention LSTM \n",
    "output_layer = Dense(len(machine_vocab), activation='softmax', name = 'output_layer')\n",
    "concat = Concatenate()\n",
    "reshaper = Reshape((n_t,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def nmt_model(Tx, Ty, n_a, n_t, human_vocab_size, machine_vocab_size, \n",
    "          dp_rate = 0.5, embed_dim = 128):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM encoder\n",
    "    n_t -- hidden state size of the post-attention LSTM decoder\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "    dp_rate -- dropout rate of dropping for the linear transformation of the inputs for LSTM\n",
    "    embed_dim -- dimension of embedded output\n",
    "\n",
    "    Returns:\n",
    "    model -- TF model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of the model with a shape (Tx,)\n",
    "    X = Input(shape=(Tx,))\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    # Encoder\n",
    "    embedded = Embedding(input_dim = human_vocab_size, output_dim = embed_dim)(X)\n",
    "    \n",
    "    # Step 1: Define pre-attention Bi-LSTM as encoder. Use return_sequences=True.\n",
    "    a, fwd_h, fwd_c, bwd_h, bwd_c = Bidirectional(LSTM(n_a,\n",
    "                                                       return_sequences = True,\n",
    "                                                       return_state = True,\n",
    "                                                       dropout = dp_rate),\n",
    "                                                  input_shape = (Tx, embed_dim))(embedded)\n",
    "    \n",
    "    # Use the final hidden state and cell memory from the encoder as the initial hidden state \n",
    "    # and cell memory of the decoder\n",
    "    h_t = concat([fwd_h, bwd_h])\n",
    "    c_t = concat([fwd_c, bwd_c])\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context \n",
    "        # vector at step t\n",
    "        # Shape: (m, 1, 2 * n_a)\n",
    "        context = one_step_attention(a, h_t)\n",
    "        \n",
    "        # Step 3.A: Apply the post-attention LSTM cell as decoder to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state]\n",
    "        # shape of out: (m, 1, n_t)\n",
    "        out, h_t, c_t = post_activation_LSTM_cell(context, initial_state = [h_t, c_t] ) \n",
    "        \n",
    "        # Step 3.B: Apply Dense layer to the hidden state output of the post-attention LSTM\n",
    "        # Shape of out: (m, n_t)\n",
    "        out = reshaper(out)\n",
    "        # Shape of out: (m, machine_vocab_size)\n",
    "        out = output_layer(out)\n",
    "        \n",
    "        # Step 3.C: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. \n",
    "    model = Model(inputs = X, outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nmt_model(Tx, Ty, n_a, n_t, len(human_vocab), len(machine_vocab), dp_rate, embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting Note\n",
    "* If you are getting repeated errors after an initially incorrect implementation of \"model\", but believe that you have corrected the error, you may still see error messages when building your model.  \n",
    "* A solution is to save and restart your kernel (or shutdown then restart your notebook), and re-run the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a summary of the model to check if it matches the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 16)       592         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 30, 128), (N 41472       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][3]              \n",
      "                                                                 bidirectional[0][2]              \n",
      "                                                                 bidirectional[0][4]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 1, 128)]     0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "atten_W_a (Dense)               (None, 30, 32)       4128        bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "atten_W_t (Dense)               (None, 1, 32)        4128        tf_op_layer_ExpandDims[0][0]     \n",
      "                                                                 tf_op_layer_ExpandDims_1[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_2[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_3[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_4[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_5[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_6[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_7[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_8[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 30, 32)]     0           atten_W_a[0][0]                  \n",
      "                                                                 atten_W_t[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "atten_scores (Dense)            (None, 30, 1)        33          tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_AddV2_1[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_2[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_3[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_4[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_5[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_6[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_7[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_8[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Softmax)     (None, 30, 1)        0           atten_scores[0][0]               \n",
      "                                                                 atten_scores[1][0]               \n",
      "                                                                 atten_scores[2][0]               \n",
      "                                                                 atten_scores[3][0]               \n",
      "                                                                 atten_scores[4][0]               \n",
      "                                                                 atten_scores[5][0]               \n",
      "                                                                 atten_scores[6][0]               \n",
      "                                                                 atten_scores[7][0]               \n",
      "                                                                 atten_scores[8][0]               \n",
      "                                                                 atten_scores[9][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 128), (None, 131584      dot_1[0][0]                      \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate[1][0]                \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm[1][1]                       \n",
      "                                                                 lstm[1][2]                       \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm[2][1]                       \n",
      "                                                                 lstm[2][2]                       \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm[3][1]                       \n",
      "                                                                 lstm[3][2]                       \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm[4][1]                       \n",
      "                                                                 lstm[4][2]                       \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm[5][1]                       \n",
      "                                                                 lstm[5][2]                       \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm[6][1]                       \n",
      "                                                                 lstm[6][2]                       \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm[7][1]                       \n",
      "                                                                 lstm[7][2]                       \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm[8][1]                       \n",
      "                                                                 lstm[8][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 128)]     0           lstm[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 30, 32)]     0           atten_W_a[1][0]                  \n",
      "                                                                 atten_W_t[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(None, 1, 128)]     0           lstm[1][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 30, 32)]     0           atten_W_a[2][0]                  \n",
      "                                                                 atten_W_t[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(None, 1, 128)]     0           lstm[2][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 30, 32)]     0           atten_W_a[3][0]                  \n",
      "                                                                 atten_W_t[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 1, 128)]     0           lstm[3][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 30, 32)]     0           atten_W_a[4][0]                  \n",
      "                                                                 atten_W_t[4][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_5 (Tenso [(None, 1, 128)]     0           lstm[4][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(None, 30, 32)]     0           atten_W_a[5][0]                  \n",
      "                                                                 atten_W_t[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_6 (Tenso [(None, 1, 128)]     0           lstm[5][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, 30, 32)]     0           atten_W_a[6][0]                  \n",
      "                                                                 atten_W_t[6][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_7 (Tenso [(None, 1, 128)]     0           lstm[6][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow [(None, 30, 32)]     0           atten_W_a[7][0]                  \n",
      "                                                                 atten_W_t[7][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_8 (Tenso [(None, 1, 128)]     0           lstm[7][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_8 (TensorFlow [(None, 30, 32)]     0           atten_W_a[8][0]                  \n",
      "                                                                 atten_W_t[8][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_9 (Tenso [(None, 1, 128)]     0           lstm[8][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_9 (TensorFlow [(None, 30, 32)]     0           atten_W_a[9][0]                  \n",
      "                                                                 atten_W_t[9][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128)          0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[5][0]                       \n",
      "                                                                 lstm[6][0]                       \n",
      "                                                                 lstm[7][0]                       \n",
      "                                                                 lstm[8][0]                       \n",
      "                                                                 lstm[9][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 11)           1419        reshape[0][0]                    \n",
      "                                                                 reshape[1][0]                    \n",
      "                                                                 reshape[2][0]                    \n",
      "                                                                 reshape[3][0]                    \n",
      "                                                                 reshape[4][0]                    \n",
      "                                                                 reshape[5][0]                    \n",
      "                                                                 reshape[6][0]                    \n",
      "                                                                 reshape[7][0]                    \n",
      "                                                                 reshape[8][0]                    \n",
      "                                                                 reshape[9][0]                    \n",
      "==================================================================================================\n",
      "Total params: 183,356\n",
      "Trainable params: 183,356\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "* After creating your model in Keras, you need to compile it and define the loss function, optimizer and metrics you want to use. \n",
    "    * Loss function: 'categorical_crossentropy'.\n",
    "    * Optimizer: [Adam](https://keras.io/optimizers/#adam) [optimizer](https://keras.io/optimizers/#usage-of-optimizers)\n",
    "        - learning rate = 0.005 \n",
    "        - $\\beta_1 = 0.9$\n",
    "        - $\\beta_2 = 0.999$\n",
    "        - decay = 0.01  \n",
    "    * metric: 'accuracy'\n",
    "    \n",
    "Sample code\n",
    "```Python\n",
    "optimizer = Adam(lr=..., beta_1=..., beta_2=..., decay=...)\n",
    "model.compile(optimizer=..., loss=..., metrics=[...])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define inputs and outputs, and fit the model\n",
    "The last step is to define all your inputs and outputs to fit the model:\n",
    "- You have input X of shape $(m = 10000, T_x = 30)$ containing the training examples.\n",
    "- Given the `model()` you coded, you need the \"outputs\" to be a list of 10 elements of shape (m, T_y). \n",
    "    - The list `outputs[i][0], ..., outputs[i][Ty]` represents the true labels (characters) corresponding to the $i^{th}$ training example (`X[i]`). \n",
    "    - `outputs[i][j]` is the true label of the $j^{th}$ character in the $i^{th}$ training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(10000, 11)\n"
     ]
    }
   ],
   "source": [
    "outputs = list(Yoh.swapaxes(0,1))\n",
    "print(len(outputs))\n",
    "print(outputs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit the model and run it for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 15.7686 - output_layer_loss: 0.9944 - output_layer_1_loss: 1.0242 - output_layer_2_loss: 1.8812 - output_layer_3_loss: 2.5527 - output_layer_4_loss: 0.5517 - output_layer_5_loss: 1.1032 - output_layer_6_loss: 2.5378 - output_layer_7_loss: 0.7637 - output_layer_8_loss: 1.6616 - output_layer_9_loss: 2.5477 - output_layer_accuracy: 0.5785 - output_layer_1_accuracy: 0.5211 - output_layer_2_accuracy: 0.1991 - output_layer_3_accuracy: 0.0828 - output_layer_4_accuracy: 0.8879 - output_layer_5_accuracy: 0.4723 - output_layer_6_accuracy: 0.0784 - output_layer_7_accuracy: 0.9374 - output_layer_8_accuracy: 0.2183 - output_layer_9_accuracy: 0.0855 - val_loss: 11.4276 - val_output_layer_loss: 0.6904 - val_output_layer_1_loss: 0.7341 - val_output_layer_2_loss: 1.7033 - val_output_layer_3_loss: 2.3319 - val_output_layer_4_loss: 0.0039 - val_output_layer_5_loss: 0.2930 - val_output_layer_6_loss: 2.0666 - val_output_layer_7_loss: 0.0019 - val_output_layer_8_loss: 1.2670 - val_output_layer_9_loss: 2.3108 - val_output_layer_accuracy: 0.5890 - val_output_layer_1_accuracy: 0.5890 - val_output_layer_2_accuracy: 0.2045 - val_output_layer_3_accuracy: 0.0965 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.8980 - val_output_layer_6_accuracy: 0.2200 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.3245 - val_output_layer_9_accuracy: 0.1040\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 11.0286 - output_layer_loss: 0.6853 - output_layer_1_loss: 0.6904 - output_layer_2_loss: 1.7002 - output_layer_3_loss: 2.3311 - output_layer_4_loss: 0.0045 - output_layer_5_loss: 0.1743 - output_layer_6_loss: 1.8527 - output_layer_7_loss: 0.0032 - output_layer_8_loss: 1.2508 - output_layer_9_loss: 2.3175 - output_layer_accuracy: 0.5830 - output_layer_1_accuracy: 0.5744 - output_layer_2_accuracy: 0.1940 - output_layer_3_accuracy: 0.1009 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9406 - output_layer_6_accuracy: 0.2734 - output_layer_7_accuracy: 0.9999 - output_layer_8_accuracy: 0.3487 - output_layer_9_accuracy: 0.1146 - val_loss: 10.6820 - val_output_layer_loss: 0.6765 - val_output_layer_1_loss: 0.6812 - val_output_layer_2_loss: 1.6805 - val_output_layer_3_loss: 2.3108 - val_output_layer_4_loss: 0.0025 - val_output_layer_5_loss: 0.1284 - val_output_layer_6_loss: 1.6240 - val_output_layer_7_loss: 0.0016 - val_output_layer_8_loss: 1.2532 - val_output_layer_9_loss: 2.3171 - val_output_layer_accuracy: 0.5890 - val_output_layer_1_accuracy: 0.5890 - val_output_layer_2_accuracy: 0.2340 - val_output_layer_3_accuracy: 0.1185 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9515 - val_output_layer_6_accuracy: 0.4035 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.3470 - val_output_layer_9_accuracy: 0.1255\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 10.2571 - output_layer_loss: 0.5699 - output_layer_1_loss: 0.5749 - output_layer_2_loss: 1.5873 - output_layer_3_loss: 2.3253 - output_layer_4_loss: 0.0016 - output_layer_5_loss: 0.1371 - output_layer_6_loss: 1.4952 - output_layer_7_loss: 0.0013 - output_layer_8_loss: 1.2496 - output_layer_9_loss: 2.3105 - output_layer_accuracy: 0.6815 - output_layer_1_accuracy: 0.6786 - output_layer_2_accuracy: 0.2720 - output_layer_3_accuracy: 0.1155 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9499 - output_layer_6_accuracy: 0.4187 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.3395 - output_layer_9_accuracy: 0.1121 - val_loss: 8.9927 - val_output_layer_loss: 0.1528 - val_output_layer_1_loss: 0.1510 - val_output_layer_2_loss: 1.1767 - val_output_layer_3_loss: 2.2941 - val_output_layer_4_loss: 7.3075e-04 - val_output_layer_5_loss: 0.1545 - val_output_layer_6_loss: 1.5264 - val_output_layer_7_loss: 4.0069e-04 - val_output_layer_8_loss: 1.2482 - val_output_layer_9_loss: 2.2847 - val_output_layer_accuracy: 0.9515 - val_output_layer_1_accuracy: 0.9510 - val_output_layer_2_accuracy: 0.4175 - val_output_layer_3_accuracy: 0.1470 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9265 - val_output_layer_6_accuracy: 0.3870 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.3695 - val_output_layer_9_accuracy: 0.1145\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 8.5911 - output_layer_loss: 0.1258 - output_layer_1_loss: 0.1283 - output_layer_2_loss: 1.1060 - output_layer_3_loss: 2.2656 - output_layer_4_loss: 0.0013 - output_layer_5_loss: 0.1407 - output_layer_6_loss: 1.2824 - output_layer_7_loss: 9.0594e-04 - output_layer_8_loss: 1.2445 - output_layer_9_loss: 2.2947 - output_layer_accuracy: 0.9541 - output_layer_1_accuracy: 0.9523 - output_layer_2_accuracy: 0.4346 - output_layer_3_accuracy: 0.1437 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9495 - output_layer_6_accuracy: 0.5034 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.3520 - output_layer_9_accuracy: 0.1219 - val_loss: 8.2974 - val_output_layer_loss: 0.1017 - val_output_layer_1_loss: 0.0974 - val_output_layer_2_loss: 1.0519 - val_output_layer_3_loss: 2.1776 - val_output_layer_4_loss: 4.9168e-04 - val_output_layer_5_loss: 0.1228 - val_output_layer_6_loss: 1.2013 - val_output_layer_7_loss: 4.7038e-04 - val_output_layer_8_loss: 1.2555 - val_output_layer_9_loss: 2.2882 - val_output_layer_accuracy: 0.9500 - val_output_layer_1_accuracy: 0.9510 - val_output_layer_2_accuracy: 0.4680 - val_output_layer_3_accuracy: 0.1835 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9625 - val_output_layer_6_accuracy: 0.5445 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.3555 - val_output_layer_9_accuracy: 0.1285\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 7.9178 - output_layer_loss: 0.0783 - output_layer_1_loss: 0.0772 - output_layer_2_loss: 1.0392 - output_layer_3_loss: 2.0324 - output_layer_4_loss: 0.0013 - output_layer_5_loss: 0.1116 - output_layer_6_loss: 1.0410 - output_layer_7_loss: 9.1707e-04 - output_layer_8_loss: 1.2422 - output_layer_9_loss: 2.2901 - output_layer_accuracy: 0.9674 - output_layer_1_accuracy: 0.9675 - output_layer_2_accuracy: 0.4575 - output_layer_3_accuracy: 0.2208 - output_layer_4_accuracy: 0.9999 - output_layer_5_accuracy: 0.9635 - output_layer_6_accuracy: 0.5981 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.3469 - output_layer_9_accuracy: 0.1275 - val_loss: 7.5962 - val_output_layer_loss: 0.0700 - val_output_layer_1_loss: 0.0701 - val_output_layer_2_loss: 1.0232 - val_output_layer_3_loss: 1.8435 - val_output_layer_4_loss: 9.1657e-04 - val_output_layer_5_loss: 0.1001 - val_output_layer_6_loss: 0.9557 - val_output_layer_7_loss: 0.0011 - val_output_layer_8_loss: 1.2436 - val_output_layer_9_loss: 2.2867 - val_output_layer_accuracy: 0.9700 - val_output_layer_1_accuracy: 0.9705 - val_output_layer_2_accuracy: 0.4400 - val_output_layer_3_accuracy: 0.2785 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9640 - val_output_layer_6_accuracy: 0.6385 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.3575 - val_output_layer_9_accuracy: 0.1230\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 7.2177 - output_layer_loss: 0.0527 - output_layer_1_loss: 0.0515 - output_layer_2_loss: 1.0024 - output_layer_3_loss: 1.6566 - output_layer_4_loss: 0.0012 - output_layer_5_loss: 0.0855 - output_layer_6_loss: 0.8598 - output_layer_7_loss: 0.0012 - output_layer_8_loss: 1.2376 - output_layer_9_loss: 2.2588 - output_layer_accuracy: 0.9790 - output_layer_1_accuracy: 0.9793 - output_layer_2_accuracy: 0.4540 - output_layer_3_accuracy: 0.3125 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9690 - output_layer_6_accuracy: 0.6730 - output_layer_7_accuracy: 0.9999 - output_layer_8_accuracy: 0.3593 - output_layer_9_accuracy: 0.1402 - val_loss: 7.0857 - val_output_layer_loss: 0.0432 - val_output_layer_1_loss: 0.0422 - val_output_layer_2_loss: 1.0110 - val_output_layer_3_loss: 1.7461 - val_output_layer_4_loss: 0.0019 - val_output_layer_5_loss: 0.0696 - val_output_layer_6_loss: 0.7860 - val_output_layer_7_loss: 7.0811e-04 - val_output_layer_8_loss: 1.2221 - val_output_layer_9_loss: 2.1364 - val_output_layer_accuracy: 0.9785 - val_output_layer_1_accuracy: 0.9805 - val_output_layer_2_accuracy: 0.4365 - val_output_layer_3_accuracy: 0.2580 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9765 - val_output_layer_6_accuracy: 0.7640 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.4015 - val_output_layer_9_accuracy: 0.1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 6.0993 - output_layer_loss: 0.0277 - output_layer_1_loss: 0.0243 - output_layer_2_loss: 0.9281 - output_layer_3_loss: 1.3489 - output_layer_4_loss: 8.6615e-04 - output_layer_5_loss: 0.0779 - output_layer_6_loss: 0.6838 - output_layer_7_loss: 0.0012 - output_layer_8_loss: 1.1544 - output_layer_9_loss: 1.8312 - output_layer_accuracy: 0.9904 - output_layer_1_accuracy: 0.9894 - output_layer_2_accuracy: 0.4970 - output_layer_3_accuracy: 0.4065 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9695 - output_layer_6_accuracy: 0.7586 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.4439 - output_layer_9_accuracy: 0.2607 - val_loss: 5.2968 - val_output_layer_loss: 0.0097 - val_output_layer_1_loss: 0.0080 - val_output_layer_2_loss: 0.8339 - val_output_layer_3_loss: 1.1289 - val_output_layer_4_loss: 0.0031 - val_output_layer_5_loss: 0.0637 - val_output_layer_6_loss: 0.5598 - val_output_layer_7_loss: 7.0844e-04 - val_output_layer_8_loss: 1.1201 - val_output_layer_9_loss: 1.5440 - val_output_layer_accuracy: 0.9990 - val_output_layer_1_accuracy: 0.9990 - val_output_layer_2_accuracy: 0.5505 - val_output_layer_3_accuracy: 0.4830 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9780 - val_output_layer_6_accuracy: 0.8025 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.4750 - val_output_layer_9_accuracy: 0.3295\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 4.6154 - output_layer_loss: 0.0057 - output_layer_1_loss: 0.0024 - output_layer_2_loss: 0.7931 - output_layer_3_loss: 1.0107 - output_layer_4_loss: 8.0719e-04 - output_layer_5_loss: 0.0643 - output_layer_6_loss: 0.4933 - output_layer_7_loss: 0.0017 - output_layer_8_loss: 0.9412 - output_layer_9_loss: 1.2719 - output_layer_accuracy: 0.9998 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.5658 - output_layer_3_accuracy: 0.5571 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9739 - output_layer_6_accuracy: 0.8361 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.5899 - output_layer_9_accuracy: 0.4439 - val_loss: 4.0022 - val_output_layer_loss: 0.0060 - val_output_layer_1_loss: 0.0050 - val_output_layer_2_loss: 0.7725 - val_output_layer_3_loss: 0.9035 - val_output_layer_4_loss: 3.9936e-04 - val_output_layer_5_loss: 0.0508 - val_output_layer_6_loss: 0.5101 - val_output_layer_7_loss: 7.5798e-04 - val_output_layer_8_loss: 0.6948 - val_output_layer_9_loss: 1.0273 - val_output_layer_accuracy: 0.9995 - val_output_layer_1_accuracy: 0.9995 - val_output_layer_2_accuracy: 0.5755 - val_output_layer_3_accuracy: 0.6150 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9790 - val_output_layer_6_accuracy: 0.8005 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.7230 - val_output_layer_9_accuracy: 0.5155\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 3.2725 - output_layer_loss: 0.0065 - output_layer_1_loss: 0.0053 - output_layer_2_loss: 0.7364 - output_layer_3_loss: 0.7289 - output_layer_4_loss: 6.2542e-04 - output_layer_5_loss: 0.0462 - output_layer_6_loss: 0.3943 - output_layer_7_loss: 0.0015 - output_layer_8_loss: 0.4851 - output_layer_9_loss: 0.8355 - output_layer_accuracy: 0.9990 - output_layer_1_accuracy: 0.9987 - output_layer_2_accuracy: 0.6083 - output_layer_3_accuracy: 0.7063 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9808 - output_layer_6_accuracy: 0.8649 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.8091 - output_layer_9_accuracy: 0.6516 - val_loss: 2.8441 - val_output_layer_loss: 0.0105 - val_output_layer_1_loss: 0.0106 - val_output_layer_2_loss: 0.7074 - val_output_layer_3_loss: 0.6338 - val_output_layer_4_loss: 4.8197e-04 - val_output_layer_5_loss: 0.0291 - val_output_layer_6_loss: 0.4795 - val_output_layer_7_loss: 5.8900e-04 - val_output_layer_8_loss: 0.2988 - val_output_layer_9_loss: 0.6404 - val_output_layer_accuracy: 0.9970 - val_output_layer_1_accuracy: 0.9960 - val_output_layer_2_accuracy: 0.6505 - val_output_layer_3_accuracy: 0.7400 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9910 - val_output_layer_6_accuracy: 0.8075 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.8810 - val_output_layer_9_accuracy: 0.7575\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 2.0870 - output_layer_loss: 0.0029 - output_layer_1_loss: 0.0019 - output_layer_2_loss: 0.5414 - output_layer_3_loss: 0.4810 - output_layer_4_loss: 4.3767e-04 - output_layer_5_loss: 0.0372 - output_layer_6_loss: 0.3145 - output_layer_7_loss: 0.0014 - output_layer_8_loss: 0.2007 - output_layer_9_loss: 0.4740 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.7452 - output_layer_3_accuracy: 0.8384 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9868 - output_layer_6_accuracy: 0.8947 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9373 - output_layer_9_accuracy: 0.8501 - val_loss: 1.4699 - val_output_layer_loss: 0.0019 - val_output_layer_1_loss: 0.0025 - val_output_layer_2_loss: 0.4052 - val_output_layer_3_loss: 0.3319 - val_output_layer_4_loss: 0.0012 - val_output_layer_5_loss: 0.0225 - val_output_layer_6_loss: 0.2652 - val_output_layer_7_loss: 0.0013 - val_output_layer_8_loss: 0.1198 - val_output_layer_9_loss: 0.2895 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.8365 - val_output_layer_3_accuracy: 0.9250 - val_output_layer_4_accuracy: 0.9990 - val_output_layer_5_accuracy: 0.9930 - val_output_layer_6_accuracy: 0.9165 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9725 - val_output_layer_9_accuracy: 0.9350\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 1.0514 - output_layer_loss: 0.0018 - output_layer_1_loss: 0.0026 - output_layer_2_loss: 0.2315 - output_layer_3_loss: 0.2534 - output_layer_4_loss: 3.0959e-04 - output_layer_5_loss: 0.0235 - output_layer_6_loss: 0.1943 - output_layer_7_loss: 9.6296e-04 - output_layer_8_loss: 0.0999 - output_layer_9_loss: 0.2171 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9342 - output_layer_3_accuracy: 0.9551 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9916 - output_layer_6_accuracy: 0.9385 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9716 - output_layer_9_accuracy: 0.9440 - val_loss: 0.8111 - val_output_layer_loss: 0.0014 - val_output_layer_1_loss: 0.0026 - val_output_layer_2_loss: 0.1323 - val_output_layer_3_loss: 0.1902 - val_output_layer_4_loss: 1.5711e-04 - val_output_layer_5_loss: 0.0175 - val_output_layer_6_loss: 0.2019 - val_output_layer_7_loss: 6.4064e-04 - val_output_layer_8_loss: 0.0819 - val_output_layer_9_loss: 0.1594 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9550 - val_output_layer_3_accuracy: 0.9730 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9930 - val_output_layer_6_accuracy: 0.9315 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9810 - val_output_layer_9_accuracy: 0.9580\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.5133 - output_layer_loss: 9.2323e-04 - output_layer_1_loss: 0.0019 - output_layer_2_loss: 0.0778 - output_layer_3_loss: 0.1135 - output_layer_4_loss: 2.9703e-04 - output_layer_5_loss: 0.0166 - output_layer_6_loss: 0.1420 - output_layer_7_loss: 6.5672e-04 - output_layer_8_loss: 0.0510 - output_layer_9_loss: 0.0893 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9797 - output_layer_3_accuracy: 0.9930 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9941 - output_layer_6_accuracy: 0.9528 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9858 - output_layer_9_accuracy: 0.9749 - val_loss: 0.5293 - val_output_layer_loss: 5.9335e-04 - val_output_layer_1_loss: 0.0013 - val_output_layer_2_loss: 0.0568 - val_output_layer_3_loss: 0.1440 - val_output_layer_4_loss: 2.1932e-04 - val_output_layer_5_loss: 0.0119 - val_output_layer_6_loss: 0.1707 - val_output_layer_7_loss: 4.2678e-04 - val_output_layer_8_loss: 0.0457 - val_output_layer_9_loss: 0.0810 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9930 - val_output_layer_3_accuracy: 0.9710 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9960 - val_output_layer_6_accuracy: 0.9440 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9900 - val_output_layer_9_accuracy: 0.9760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.3940 - output_layer_loss: 7.4469e-04 - output_layer_1_loss: 0.0015 - output_layer_2_loss: 0.0426 - output_layer_3_loss: 0.1170 - output_layer_4_loss: 2.7606e-04 - output_layer_5_loss: 0.0137 - output_layer_6_loss: 0.1146 - output_layer_7_loss: 5.3910e-04 - output_layer_8_loss: 0.0355 - output_layer_9_loss: 0.0515 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 0.9999 - output_layer_2_accuracy: 0.9920 - output_layer_3_accuracy: 0.9754 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9950 - output_layer_6_accuracy: 0.9581 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9893 - output_layer_9_accuracy: 0.9851 - val_loss: 0.3632 - val_output_layer_loss: 7.1950e-04 - val_output_layer_1_loss: 0.0015 - val_output_layer_2_loss: 0.0314 - val_output_layer_3_loss: 0.0723 - val_output_layer_4_loss: 5.4479e-05 - val_output_layer_5_loss: 0.0110 - val_output_layer_6_loss: 0.1272 - val_output_layer_7_loss: 2.9202e-04 - val_output_layer_8_loss: 0.0307 - val_output_layer_9_loss: 0.0728 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9940 - val_output_layer_3_accuracy: 0.9925 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9960 - val_output_layer_6_accuracy: 0.9520 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9920 - val_output_layer_9_accuracy: 0.9775\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.2385 - output_layer_loss: 5.1067e-04 - output_layer_1_loss: 8.3057e-04 - output_layer_2_loss: 0.0188 - output_layer_3_loss: 0.0505 - output_layer_4_loss: 7.7322e-05 - output_layer_5_loss: 0.0083 - output_layer_6_loss: 0.0834 - output_layer_7_loss: 4.1344e-04 - output_layer_8_loss: 0.0250 - output_layer_9_loss: 0.0365 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9981 - output_layer_3_accuracy: 0.9955 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9971 - output_layer_6_accuracy: 0.9725 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9930 - output_layer_9_accuracy: 0.9904 - val_loss: 0.2517 - val_output_layer_loss: 4.5347e-04 - val_output_layer_1_loss: 7.9143e-04 - val_output_layer_2_loss: 0.0129 - val_output_layer_3_loss: 0.0406 - val_output_layer_4_loss: 6.8285e-05 - val_output_layer_5_loss: 0.0073 - val_output_layer_6_loss: 0.1006 - val_output_layer_7_loss: 2.4163e-04 - val_output_layer_8_loss: 0.0275 - val_output_layer_9_loss: 0.0471 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9985 - val_output_layer_3_accuracy: 0.9980 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9975 - val_output_layer_6_accuracy: 0.9640 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9930 - val_output_layer_9_accuracy: 0.9850\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.1813 - output_layer_loss: 3.9101e-04 - output_layer_1_loss: 5.2412e-04 - output_layer_2_loss: 0.0120 - output_layer_3_loss: 0.0361 - output_layer_4_loss: 6.0053e-05 - output_layer_5_loss: 0.0062 - output_layer_6_loss: 0.0659 - output_layer_7_loss: 3.2486e-04 - output_layer_8_loss: 0.0197 - output_layer_9_loss: 0.0268 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9987 - output_layer_3_accuracy: 0.9971 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9984 - output_layer_6_accuracy: 0.9779 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9946 - output_layer_9_accuracy: 0.9924 - val_loss: 0.2276 - val_output_layer_loss: 3.7976e-04 - val_output_layer_1_loss: 4.2285e-04 - val_output_layer_2_loss: 0.0133 - val_output_layer_3_loss: 0.0361 - val_output_layer_4_loss: 6.9347e-05 - val_output_layer_5_loss: 0.0117 - val_output_layer_6_loss: 0.0876 - val_output_layer_7_loss: 4.7331e-04 - val_output_layer_8_loss: 0.0225 - val_output_layer_9_loss: 0.0398 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9980 - val_output_layer_3_accuracy: 0.9975 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9965 - val_output_layer_6_accuracy: 0.9700 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9940 - val_output_layer_9_accuracy: 0.9870\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.1478 - output_layer_loss: 2.9229e-04 - output_layer_1_loss: 3.5251e-04 - output_layer_2_loss: 0.0093 - output_layer_3_loss: 0.0350 - output_layer_4_loss: 6.2597e-05 - output_layer_5_loss: 0.0052 - output_layer_6_loss: 0.0515 - output_layer_7_loss: 3.3376e-04 - output_layer_8_loss: 0.0129 - output_layer_9_loss: 0.0195 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9992 - output_layer_3_accuracy: 0.9965 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9986 - output_layer_6_accuracy: 0.9837 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9974 - output_layer_9_accuracy: 0.9948 - val_loss: 0.1758 - val_output_layer_loss: 2.8006e-04 - val_output_layer_1_loss: 4.3754e-04 - val_output_layer_2_loss: 0.0110 - val_output_layer_3_loss: 0.0370 - val_output_layer_4_loss: 6.1928e-05 - val_output_layer_5_loss: 0.0037 - val_output_layer_6_loss: 0.0739 - val_output_layer_7_loss: 2.3424e-04 - val_output_layer_8_loss: 0.0116 - val_output_layer_9_loss: 0.0270 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9985 - val_output_layer_3_accuracy: 0.9960 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9985 - val_output_layer_6_accuracy: 0.9750 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9970 - val_output_layer_9_accuracy: 0.9935\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.1245 - output_layer_loss: 2.6920e-04 - output_layer_1_loss: 3.3603e-04 - output_layer_2_loss: 0.0108 - output_layer_3_loss: 0.0303 - output_layer_4_loss: 6.1214e-05 - output_layer_5_loss: 0.0030 - output_layer_6_loss: 0.0379 - output_layer_7_loss: 2.9458e-04 - output_layer_8_loss: 0.0122 - output_layer_9_loss: 0.0185 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9983 - output_layer_3_accuracy: 0.9962 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9994 - output_layer_6_accuracy: 0.9902 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9967 - output_layer_9_accuracy: 0.9950 - val_loss: 0.1930 - val_output_layer_loss: 2.8636e-04 - val_output_layer_1_loss: 3.3998e-04 - val_output_layer_2_loss: 0.0072 - val_output_layer_3_loss: 0.0358 - val_output_layer_4_loss: 2.8650e-05 - val_output_layer_5_loss: 0.0077 - val_output_layer_6_loss: 0.0820 - val_output_layer_7_loss: 1.9990e-04 - val_output_layer_8_loss: 0.0167 - val_output_layer_9_loss: 0.0320 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9995 - val_output_layer_3_accuracy: 0.9970 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9975 - val_output_layer_6_accuracy: 0.9715 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9945 - val_output_layer_9_accuracy: 0.9910\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0988 - output_layer_loss: 2.1870e-04 - output_layer_1_loss: 2.7698e-04 - output_layer_2_loss: 0.0076 - output_layer_3_loss: 0.0255 - output_layer_4_loss: 3.3344e-05 - output_layer_5_loss: 0.0031 - output_layer_6_loss: 0.0332 - output_layer_7_loss: 2.3163e-04 - output_layer_8_loss: 0.0077 - output_layer_9_loss: 0.0117 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9984 - output_layer_3_accuracy: 0.9976 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9992 - output_layer_6_accuracy: 0.9899 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9985 - output_layer_9_accuracy: 0.9964 - val_loss: 0.1249 - val_output_layer_loss: 3.9880e-04 - val_output_layer_1_loss: 3.3509e-04 - val_output_layer_2_loss: 0.0049 - val_output_layer_3_loss: 0.0278 - val_output_layer_4_loss: 3.1635e-05 - val_output_layer_5_loss: 0.0020 - val_output_layer_6_loss: 0.0507 - val_output_layer_7_loss: 2.4504e-04 - val_output_layer_8_loss: 0.0102 - val_output_layer_9_loss: 0.0202 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9995 - val_output_layer_3_accuracy: 0.9980 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9995 - val_output_layer_6_accuracy: 0.9815 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9955 - val_output_layer_9_accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0927 - output_layer_loss: 2.0418e-04 - output_layer_1_loss: 2.5374e-04 - output_layer_2_loss: 0.0046 - output_layer_3_loss: 0.0201 - output_layer_4_loss: 3.8906e-05 - output_layer_5_loss: 0.0043 - output_layer_6_loss: 0.0329 - output_layer_7_loss: 2.2285e-04 - output_layer_8_loss: 0.0094 - output_layer_9_loss: 0.0115 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9996 - output_layer_3_accuracy: 0.9977 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9987 - output_layer_6_accuracy: 0.9915 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9970 - output_layer_9_accuracy: 0.9967 - val_loss: 0.1415 - val_output_layer_loss: 5.4265e-04 - val_output_layer_1_loss: 3.5193e-04 - val_output_layer_2_loss: 0.0058 - val_output_layer_3_loss: 0.0279 - val_output_layer_4_loss: 3.8480e-05 - val_output_layer_5_loss: 0.0026 - val_output_layer_6_loss: 0.0610 - val_output_layer_7_loss: 2.2447e-04 - val_output_layer_8_loss: 0.0116 - val_output_layer_9_loss: 0.0206 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9995 - val_output_layer_3_accuracy: 0.9980 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9990 - val_output_layer_6_accuracy: 0.9785 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9950 - val_output_layer_9_accuracy: 0.9935\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.1984 - output_layer_loss: 7.6410e-04 - output_layer_1_loss: 6.5380e-04 - output_layer_2_loss: 0.0135 - output_layer_3_loss: 0.0408 - output_layer_4_loss: 4.3795e-05 - output_layer_5_loss: 0.0073 - output_layer_6_loss: 0.0500 - output_layer_7_loss: 5.7374e-04 - output_layer_8_loss: 0.0328 - output_layer_9_loss: 0.0271 - output_layer_accuracy: 0.9999 - output_layer_1_accuracy: 0.9998 - output_layer_2_accuracy: 0.9971 - output_layer_3_accuracy: 0.9908 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9980 - output_layer_6_accuracy: 0.9845 - output_layer_7_accuracy: 0.9999 - output_layer_8_accuracy: 0.9884 - output_layer_9_accuracy: 0.9923 - val_loss: 0.2475 - val_output_layer_loss: 0.0120 - val_output_layer_1_loss: 0.0191 - val_output_layer_2_loss: 0.0195 - val_output_layer_3_loss: 0.0427 - val_output_layer_4_loss: 6.7981e-05 - val_output_layer_5_loss: 0.0046 - val_output_layer_6_loss: 0.0676 - val_output_layer_7_loss: 1.5059e-04 - val_output_layer_8_loss: 0.0252 - val_output_layer_9_loss: 0.0324 - val_output_layer_accuracy: 0.9970 - val_output_layer_1_accuracy: 0.9955 - val_output_layer_2_accuracy: 0.9950 - val_output_layer_3_accuracy: 0.9935 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9995 - val_output_layer_6_accuracy: 0.9765 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9925 - val_output_layer_9_accuracy: 0.9910\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.1074 - output_layer_loss: 0.0012 - output_layer_1_loss: 0.0023 - output_layer_2_loss: 0.0087 - output_layer_3_loss: 0.0263 - output_layer_4_loss: 2.9779e-05 - output_layer_5_loss: 0.0036 - output_layer_6_loss: 0.0239 - output_layer_7_loss: 1.9430e-04 - output_layer_8_loss: 0.0098 - output_layer_9_loss: 0.0138 - output_layer_accuracy: 0.9996 - output_layer_1_accuracy: 0.9996 - output_layer_2_accuracy: 0.9986 - output_layer_3_accuracy: 0.9962 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9989 - output_layer_6_accuracy: 0.9939 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9975 - output_layer_9_accuracy: 0.9956 - val_loss: 0.1058 - val_output_layer_loss: 1.1548e-04 - val_output_layer_1_loss: 1.7903e-04 - val_output_layer_2_loss: 0.0078 - val_output_layer_3_loss: 0.0258 - val_output_layer_4_loss: 2.2720e-05 - val_output_layer_5_loss: 0.0010 - val_output_layer_6_loss: 0.0347 - val_output_layer_7_loss: 1.2601e-04 - val_output_layer_8_loss: 0.0068 - val_output_layer_9_loss: 0.0167 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9985 - val_output_layer_3_accuracy: 0.9980 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9870 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9980 - val_output_layer_9_accuracy: 0.9950\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0523 - output_layer_loss: 1.0267e-04 - output_layer_1_loss: 1.6235e-04 - output_layer_2_loss: 0.0034 - output_layer_3_loss: 0.0151 - output_layer_4_loss: 2.8557e-05 - output_layer_5_loss: 0.0027 - output_layer_6_loss: 0.0135 - output_layer_7_loss: 1.3052e-04 - output_layer_8_loss: 0.0031 - output_layer_9_loss: 0.0049 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9995 - output_layer_3_accuracy: 0.9977 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9991 - output_layer_6_accuracy: 0.9974 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9994 - output_layer_9_accuracy: 0.9989 - val_loss: 0.0983 - val_output_layer_loss: 9.3839e-05 - val_output_layer_1_loss: 1.5722e-04 - val_output_layer_2_loss: 0.0023 - val_output_layer_3_loss: 0.0223 - val_output_layer_4_loss: 2.5835e-05 - val_output_layer_5_loss: 0.0059 - val_output_layer_6_loss: 0.0380 - val_output_layer_7_loss: 1.2573e-04 - val_output_layer_8_loss: 0.0074 - val_output_layer_9_loss: 0.0145 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 1.0000 - val_output_layer_3_accuracy: 0.9980 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 0.9990 - val_output_layer_6_accuracy: 0.9870 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9970 - val_output_layer_9_accuracy: 0.9955\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0389 - output_layer_loss: 9.6171e-05 - output_layer_1_loss: 1.5745e-04 - output_layer_2_loss: 0.0038 - output_layer_3_loss: 0.0130 - output_layer_4_loss: 3.2242e-05 - output_layer_5_loss: 0.0017 - output_layer_6_loss: 0.0086 - output_layer_7_loss: 1.3041e-04 - output_layer_8_loss: 0.0024 - output_layer_9_loss: 0.0031 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9991 - output_layer_3_accuracy: 0.9979 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 0.9992 - output_layer_6_accuracy: 0.9990 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9994 - output_layer_9_accuracy: 0.9994 - val_loss: 0.0697 - val_output_layer_loss: 9.5677e-05 - val_output_layer_1_loss: 1.4861e-04 - val_output_layer_2_loss: 0.0018 - val_output_layer_3_loss: 0.0228 - val_output_layer_4_loss: 3.2502e-05 - val_output_layer_5_loss: 5.4525e-04 - val_output_layer_6_loss: 0.0224 - val_output_layer_7_loss: 1.3571e-04 - val_output_layer_8_loss: 0.0054 - val_output_layer_9_loss: 0.0112 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 1.0000 - val_output_layer_3_accuracy: 0.9980 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9915 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9975 - val_output_layer_9_accuracy: 0.9955\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0315 - output_layer_loss: 8.6888e-05 - output_layer_1_loss: 1.3814e-04 - output_layer_2_loss: 0.0020 - output_layer_3_loss: 0.0119 - output_layer_4_loss: 3.2882e-05 - output_layer_5_loss: 4.3589e-04 - output_layer_6_loss: 0.0059 - output_layer_7_loss: 1.0602e-04 - output_layer_8_loss: 0.0019 - output_layer_9_loss: 0.0044 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9998 - output_layer_3_accuracy: 0.9984 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 1.0000 - output_layer_6_accuracy: 0.9995 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9999 - output_layer_9_accuracy: 0.9990 - val_loss: 0.0863 - val_output_layer_loss: 8.3279e-05 - val_output_layer_1_loss: 1.2284e-04 - val_output_layer_2_loss: 0.0016 - val_output_layer_3_loss: 0.0219 - val_output_layer_4_loss: 3.9483e-05 - val_output_layer_5_loss: 4.6172e-04 - val_output_layer_6_loss: 0.0233 - val_output_layer_7_loss: 6.8984e-05 - val_output_layer_8_loss: 0.0066 - val_output_layer_9_loss: 0.0278 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 1.0000 - val_output_layer_3_accuracy: 0.9980 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9920 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9975 - val_output_layer_9_accuracy: 0.9910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0369 - output_layer_loss: 8.4557e-05 - output_layer_1_loss: 1.7664e-04 - output_layer_2_loss: 0.0022 - output_layer_3_loss: 0.0104 - output_layer_4_loss: 4.1099e-05 - output_layer_5_loss: 5.2041e-04 - output_layer_6_loss: 0.0063 - output_layer_7_loss: 1.2017e-04 - output_layer_8_loss: 0.0032 - output_layer_9_loss: 0.0086 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9998 - output_layer_3_accuracy: 0.9979 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 1.0000 - output_layer_6_accuracy: 0.9995 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9992 - output_layer_9_accuracy: 0.9981 - val_loss: 0.1155 - val_output_layer_loss: 7.5184e-05 - val_output_layer_1_loss: 1.3460e-04 - val_output_layer_2_loss: 0.0051 - val_output_layer_3_loss: 0.0368 - val_output_layer_4_loss: 4.5578e-05 - val_output_layer_5_loss: 5.3534e-04 - val_output_layer_6_loss: 0.0280 - val_output_layer_7_loss: 1.9162e-04 - val_output_layer_8_loss: 0.0112 - val_output_layer_9_loss: 0.0257 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9985 - val_output_layer_3_accuracy: 0.9930 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9900 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9980 - val_output_layer_9_accuracy: 0.9905\n",
      "Epoch 26/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0296 - output_layer_loss: 7.7568e-05 - output_layer_1_loss: 1.0289e-04 - output_layer_2_loss: 0.0020 - output_layer_3_loss: 0.0099 - output_layer_4_loss: 2.8820e-05 - output_layer_5_loss: 3.8114e-04 - output_layer_6_loss: 0.0054 - output_layer_7_loss: 1.5601e-04 - output_layer_8_loss: 0.0018 - output_layer_9_loss: 0.0027 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9999 - output_layer_3_accuracy: 0.9980 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 1.0000 - output_layer_6_accuracy: 0.9999 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 0.9998 - output_layer_9_accuracy: 0.9995 - val_loss: 0.0582 - val_output_layer_loss: 7.0859e-05 - val_output_layer_1_loss: 9.5832e-05 - val_output_layer_2_loss: 0.0019 - val_output_layer_3_loss: 0.0206 - val_output_layer_4_loss: 2.7683e-05 - val_output_layer_5_loss: 6.1064e-04 - val_output_layer_6_loss: 0.0204 - val_output_layer_7_loss: 5.4100e-05 - val_output_layer_8_loss: 0.0041 - val_output_layer_9_loss: 0.0058 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9995 - val_output_layer_3_accuracy: 0.9975 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9920 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9985 - val_output_layer_9_accuracy: 0.9980\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0175 - output_layer_loss: 6.6678e-05 - output_layer_1_loss: 9.7408e-05 - output_layer_2_loss: 0.0023 - output_layer_3_loss: 0.0072 - output_layer_4_loss: 2.5153e-05 - output_layer_5_loss: 2.9259e-04 - output_layer_6_loss: 0.0025 - output_layer_7_loss: 5.8275e-05 - output_layer_8_loss: 8.2324e-04 - output_layer_9_loss: 8.6875e-04 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9996 - output_layer_3_accuracy: 0.9985 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 1.0000 - output_layer_6_accuracy: 1.0000 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 1.0000 - output_layer_9_accuracy: 1.0000 - val_loss: 0.0607 - val_output_layer_loss: 6.5479e-05 - val_output_layer_1_loss: 1.1623e-04 - val_output_layer_2_loss: 0.0070 - val_output_layer_3_loss: 0.0255 - val_output_layer_4_loss: 1.8540e-05 - val_output_layer_5_loss: 3.0215e-04 - val_output_layer_6_loss: 0.0166 - val_output_layer_7_loss: 5.2336e-05 - val_output_layer_8_loss: 0.0029 - val_output_layer_9_loss: 0.0057 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9985 - val_output_layer_3_accuracy: 0.9965 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9930 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9990 - val_output_layer_9_accuracy: 0.9980\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.0137 - output_layer_loss: 6.1841e-05 - output_layer_1_loss: 9.2862e-05 - output_layer_2_loss: 0.0015 - output_layer_3_loss: 0.0067 - output_layer_4_loss: 2.5174e-05 - output_layer_5_loss: 1.6901e-04 - output_layer_6_loss: 0.0019 - output_layer_7_loss: 4.7276e-05 - output_layer_8_loss: 5.2507e-04 - output_layer_9_loss: 6.6160e-04 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9999 - output_layer_3_accuracy: 0.9990 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 1.0000 - output_layer_6_accuracy: 1.0000 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 1.0000 - output_layer_9_accuracy: 1.0000 - val_loss: 0.0511 - val_output_layer_loss: 5.7151e-05 - val_output_layer_1_loss: 9.7720e-05 - val_output_layer_2_loss: 0.0012 - val_output_layer_3_loss: 0.0233 - val_output_layer_4_loss: 1.9184e-05 - val_output_layer_5_loss: 5.0298e-04 - val_output_layer_6_loss: 0.0150 - val_output_layer_7_loss: 5.4724e-05 - val_output_layer_8_loss: 0.0031 - val_output_layer_9_loss: 0.0062 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 1.0000 - val_output_layer_3_accuracy: 0.9975 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9935 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9995 - val_output_layer_9_accuracy: 0.9985\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.0116 - output_layer_loss: 5.4998e-05 - output_layer_1_loss: 8.8975e-05 - output_layer_2_loss: 0.0013 - output_layer_3_loss: 0.0057 - output_layer_4_loss: 2.1291e-05 - output_layer_5_loss: 1.7022e-04 - output_layer_6_loss: 0.0017 - output_layer_7_loss: 4.2312e-05 - output_layer_8_loss: 5.1221e-04 - output_layer_9_loss: 6.2603e-04 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9998 - output_layer_3_accuracy: 0.9987 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 1.0000 - output_layer_6_accuracy: 1.0000 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 1.0000 - output_layer_9_accuracy: 1.0000 - val_loss: 0.0575 - val_output_layer_loss: 5.5577e-05 - val_output_layer_1_loss: 8.9552e-05 - val_output_layer_2_loss: 0.0038 - val_output_layer_3_loss: 0.0247 - val_output_layer_4_loss: 2.2281e-05 - val_output_layer_5_loss: 3.8038e-04 - val_output_layer_6_loss: 0.0160 - val_output_layer_7_loss: 5.2956e-05 - val_output_layer_8_loss: 0.0031 - val_output_layer_9_loss: 0.0078 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9990 - val_output_layer_3_accuracy: 0.9965 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9930 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9990 - val_output_layer_9_accuracy: 0.9970\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 4s 54ms/step - loss: 0.0098 - output_layer_loss: 5.3718e-05 - output_layer_1_loss: 8.9209e-05 - output_layer_2_loss: 0.0012 - output_layer_3_loss: 0.0045 - output_layer_4_loss: 2.4243e-05 - output_layer_5_loss: 1.6214e-04 - output_layer_6_loss: 0.0015 - output_layer_7_loss: 3.8575e-05 - output_layer_8_loss: 4.0580e-04 - output_layer_9_loss: 5.3906e-04 - output_layer_accuracy: 1.0000 - output_layer_1_accuracy: 1.0000 - output_layer_2_accuracy: 0.9999 - output_layer_3_accuracy: 0.9991 - output_layer_4_accuracy: 1.0000 - output_layer_5_accuracy: 1.0000 - output_layer_6_accuracy: 1.0000 - output_layer_7_accuracy: 1.0000 - output_layer_8_accuracy: 1.0000 - output_layer_9_accuracy: 1.0000 - val_loss: 0.0516 - val_output_layer_loss: 5.2318e-05 - val_output_layer_1_loss: 1.0079e-04 - val_output_layer_2_loss: 0.0013 - val_output_layer_3_loss: 0.0233 - val_output_layer_4_loss: 1.9203e-05 - val_output_layer_5_loss: 2.6136e-04 - val_output_layer_6_loss: 0.0139 - val_output_layer_7_loss: 3.6756e-05 - val_output_layer_8_loss: 0.0031 - val_output_layer_9_loss: 0.0084 - val_output_layer_accuracy: 1.0000 - val_output_layer_1_accuracy: 1.0000 - val_output_layer_2_accuracy: 0.9995 - val_output_layer_3_accuracy: 0.9970 - val_output_layer_4_accuracy: 1.0000 - val_output_layer_5_accuracy: 1.0000 - val_output_layer_6_accuracy: 0.9940 - val_output_layer_7_accuracy: 1.0000 - val_output_layer_8_accuracy: 0.9995 - val_output_layer_9_accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, outputs, \n",
    "                    epochs = epochs, \n",
    "                    batch_size = 100,\n",
    "                    validation_split = 0.2,\n",
    "                    verbose = 1,\n",
    "                    callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'loss', \n",
    "                                                                  patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'output_layer_loss', 'output_layer_1_loss', 'output_layer_2_loss', 'output_layer_3_loss', 'output_layer_4_loss', 'output_layer_5_loss', 'output_layer_6_loss', 'output_layer_7_loss', 'output_layer_8_loss', 'output_layer_9_loss', 'output_layer_accuracy', 'output_layer_1_accuracy', 'output_layer_2_accuracy', 'output_layer_3_accuracy', 'output_layer_4_accuracy', 'output_layer_5_accuracy', 'output_layer_6_accuracy', 'output_layer_7_accuracy', 'output_layer_8_accuracy', 'output_layer_9_accuracy', 'val_loss', 'val_output_layer_loss', 'val_output_layer_1_loss', 'val_output_layer_2_loss', 'val_output_layer_3_loss', 'val_output_layer_4_loss', 'val_output_layer_5_loss', 'val_output_layer_6_loss', 'val_output_layer_7_loss', 'val_output_layer_8_loss', 'val_output_layer_9_loss', 'val_output_layer_accuracy', 'val_output_layer_1_accuracy', 'val_output_layer_2_accuracy', 'val_output_layer_3_accuracy', 'val_output_layer_4_accuracy', 'val_output_layer_5_accuracy', 'val_output_layer_6_accuracy', 'val_output_layer_7_accuracy', 'val_output_layer_8_accuracy', 'val_output_layer_9_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss'] \n",
    "\n",
    "acc = history.history['output_layer_9_accuracy'] \n",
    "val_acc = history.history['val_output_layer_9_accuracy'] \n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8)) \n",
    "plt.subplot(2, 1, 1) \n",
    "plt.plot(epochs_range, acc, label='Training Accuracy') \n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy') \n",
    "plt.legend(loc='lower right') \n",
    "plt.title('Training and Validation Accuracy') \n",
    "\n",
    "plt.subplot(2, 1, 2) \n",
    "# plt.ylim(0, 5)\n",
    "plt.plot(epochs_range, loss, label='Training Loss') \n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss') \n",
    "plt.legend(loc='upper right') \n",
    "plt.title('Training and Validation Loss') \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training you can see the loss as well as the accuracy on each of the 10 positions of the output. The table below gives you an example of what the accuracies could be if the batch had 2 examples: \n",
    "\n",
    "<img src=\"images/table.png\" style=\"width:700;height:200px;\"> <br>\n",
    "<caption><center>Thus, `dense_2_acc_8: 0.89` means that you are predicting the 7th character of the output correctly 89% of the time in the current batch of data. </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now see the results on new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 0, 24, 13, 34, 0, 4, 12, 10, 12, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36]\n"
     ]
    }
   ],
   "source": [
    "source = string_to_int('3 May 1979', Tx, human_vocab)\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: Wed 10 10 2009\n",
      "output: 2009-12-10 \n",
      "\n",
      "source: 5 April 09\n",
      "output: 2099-04-05 \n",
      "\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21 \n",
      "\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10 \n",
      "\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09 \n",
      "\n",
      "source: March 3 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "source: 11 March 2001\n",
      "output: 2001-03-11 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['Wed 10 10 2009', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '11 March 2001']\n",
    "for example in EXAMPLES:\n",
    "    \n",
    "    source = np.array(string_to_int(example, Tx, human_vocab)).reshape(1, -1)\n",
    "    prediction = model.predict(source)\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change these examples to test with your own examples. The next part will give you a better sense of what the attention mechanism is doing--i.e., what part of the input the network is paying attention to when generating a particular output character. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Visualizing Attention (Optional / Ungraded)\n",
    "\n",
    "Since the problem has a fixed output length of 10, it is also possible to carry out this task using 10 different softmax units to generate the 10 characters of the output. But one advantage of the attention model is that each part of the output (such as the month) knows it needs to depend only on a small part of the input (the characters in the input giving the month). We can  visualize what each part of the output is looking at which part of the input.\n",
    "\n",
    "Consider the task of translating \"Saturday 9 May 2018\" to \"2018-05-09\". If we visualize the computed $\\alpha^{\\langle t, t' \\rangle}$ we get this: \n",
    "\n",
    "<img src=\"images/date_attention.png\" style=\"width:600;height:300px;\"> <br>\n",
    "<caption><center> **Figure 8**: Full Attention Map</center></caption>\n",
    "\n",
    "Notice how the output ignores the \"Saturday\" portion of the input. None of the output timesteps are paying much attention to that portion of the input. We also see that 9 has been translated as 09 and May has been correctly translated into 05, with the output paying attention to the parts of the input it needs to to make the translation. The year mostly requires it to pay attention to the input's \"18\" in order to generate \"2018.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Getting the attention weights from the network\n",
    "\n",
    "Lets now visualize the attention values in your network. We'll propagate an example through the network, then visualize the values of $\\alpha^{\\langle t, t' \\rangle}$. \n",
    "\n",
    "To figure out where the attention values are located, let's start by printing a summary of the model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 16)       592         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 30, 128), (N 41472       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][3]              \n",
      "                                                                 bidirectional[0][2]              \n",
      "                                                                 bidirectional[0][4]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 1, 128)]     0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "atten_W_a (Dense)               (None, 30, 32)       4128        bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "atten_W_t (Dense)               (None, 1, 32)        4128        tf_op_layer_ExpandDims[0][0]     \n",
      "                                                                 tf_op_layer_ExpandDims_1[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_2[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_3[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_4[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_5[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_6[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_7[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_8[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 30, 32)]     0           atten_W_a[0][0]                  \n",
      "                                                                 atten_W_t[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "atten_scores (Dense)            (None, 30, 1)        33          tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_AddV2_1[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_2[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_3[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_4[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_5[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_6[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_7[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_8[0][0]        \n",
      "                                                                 tf_op_layer_AddV2_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Softmax)     (None, 30, 1)        0           atten_scores[0][0]               \n",
      "                                                                 atten_scores[1][0]               \n",
      "                                                                 atten_scores[2][0]               \n",
      "                                                                 atten_scores[3][0]               \n",
      "                                                                 atten_scores[4][0]               \n",
      "                                                                 atten_scores[5][0]               \n",
      "                                                                 atten_scores[6][0]               \n",
      "                                                                 atten_scores[7][0]               \n",
      "                                                                 atten_scores[8][0]               \n",
      "                                                                 atten_scores[9][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 128), (None, 131584      dot_1[0][0]                      \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate[1][0]                \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm[1][1]                       \n",
      "                                                                 lstm[1][2]                       \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm[2][1]                       \n",
      "                                                                 lstm[2][2]                       \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm[3][1]                       \n",
      "                                                                 lstm[3][2]                       \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm[4][1]                       \n",
      "                                                                 lstm[4][2]                       \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm[5][1]                       \n",
      "                                                                 lstm[5][2]                       \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm[6][1]                       \n",
      "                                                                 lstm[6][2]                       \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm[7][1]                       \n",
      "                                                                 lstm[7][2]                       \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm[8][1]                       \n",
      "                                                                 lstm[8][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 128)]     0           lstm[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 30, 32)]     0           atten_W_a[1][0]                  \n",
      "                                                                 atten_W_t[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(None, 1, 128)]     0           lstm[1][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 30, 32)]     0           atten_W_a[2][0]                  \n",
      "                                                                 atten_W_t[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(None, 1, 128)]     0           lstm[2][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 30, 32)]     0           atten_W_a[3][0]                  \n",
      "                                                                 atten_W_t[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 1, 128)]     0           lstm[3][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 30, 32)]     0           atten_W_a[4][0]                  \n",
      "                                                                 atten_W_t[4][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_5 (Tenso [(None, 1, 128)]     0           lstm[4][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(None, 30, 32)]     0           atten_W_a[5][0]                  \n",
      "                                                                 atten_W_t[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_6 (Tenso [(None, 1, 128)]     0           lstm[5][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, 30, 32)]     0           atten_W_a[6][0]                  \n",
      "                                                                 atten_W_t[6][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_7 (Tenso [(None, 1, 128)]     0           lstm[6][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow [(None, 30, 32)]     0           atten_W_a[7][0]                  \n",
      "                                                                 atten_W_t[7][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_8 (Tenso [(None, 1, 128)]     0           lstm[7][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_8 (TensorFlow [(None, 30, 32)]     0           atten_W_a[8][0]                  \n",
      "                                                                 atten_W_t[8][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_9 (Tenso [(None, 1, 128)]     0           lstm[8][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_9 (TensorFlow [(None, 30, 32)]     0           atten_W_a[9][0]                  \n",
      "                                                                 atten_W_t[9][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128)          0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[5][0]                       \n",
      "                                                                 lstm[6][0]                       \n",
      "                                                                 lstm[7][0]                       \n",
      "                                                                 lstm[8][0]                       \n",
      "                                                                 lstm[9][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 11)           1419        reshape[0][0]                    \n",
      "                                                                 reshape[1][0]                    \n",
      "                                                                 reshape[2][0]                    \n",
      "                                                                 reshape[3][0]                    \n",
      "                                                                 reshape[4][0]                    \n",
      "                                                                 reshape[5][0]                    \n",
      "                                                                 reshape[6][0]                    \n",
      "                                                                 reshape[7][0]                    \n",
      "                                                                 reshape[8][0]                    \n",
      "                                                                 reshape[9][0]                    \n",
      "==================================================================================================\n",
      "Total params: 183,356\n",
      "Trainable params: 183,356\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate through the output of `model.summary()` above. You can see that the layer named `attention_weights` outputs the `alphas` of shape (m, 30, 1) before `dot_2` computes the context vector for every time step $t = 0, \\ldots, T_y-1$. Let's get the attention weights from this layer.\n",
    "\n",
    "The function `attention_map()` pulls out the attention values from your model and plots them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x612 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model,\n",
    "                                   human_vocab,\n",
    "                                   inv_machine_vocab, \n",
    "                                   \"Tuesday 3 April 1987\", \n",
    "                                   \"attention_weights\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the generated plot you can observe the values of the attention weights for each character of the predicted output. Examine this plot and check that the places where the network is paying attention makes sense to you.\n",
    "\n",
    "In the date translation application, you will observe that most of the time attention helps predict the year, and doesn't have much impact on predicting the day or month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "\n",
    "You have come to the end of this assignment \n",
    "\n",
    "## Here's what you should remember\n",
    "\n",
    "- Machine translation models can be used to map from one sequence to another. They are useful not just for translating human languages (like French->English) but also for tasks like date format translation. \n",
    "- An attention mechanism allows a network to focus on the most relevant parts of the input when producing a specific part of the output. \n",
    "- A network using an attention mechanism can translate from inputs of length $T_x$ to outputs of length $T_y$, where $T_x$ and $T_y$ can be different. \n",
    "- You can visualize attention weights $\\alpha^{\\langle t,t' \\rangle}$ to see what the network is paying attention to while generating each output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing this assignment! You are now able to implement an attention model and use it to learn complex mappings from one sequence to another. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "n16CQ",
   "launcher_item_id": "npjGi"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
